---
title: Irisデータ処理（機械学習：前処理編）
tags:
  - Python
  - 機械学習
  - 前処理
  - iris
private: false
updated_at: '2021-09-12T22:40:06+09:00'
id: c5a43b67ec9f96972252
organization_url_name: null
slide: false
ignorePublish: false
---
##機械学習の全体の流れ
➀データの取得
➁データの加工(標準化、テスト用データと学習用データの分割など）
➂モデルの定義を行い、データを入力する。
➃機械学習を行う。（順伝播と逆伝播を繰り返し、精度を上げていく）
➄機械学習の結果を評価する。問題があれば、チューニングを行う。

今回は前処理に分類される➀と➁について整理したい。

##今回使用したPythonテクニック
➀One-Hot表記
➁内包表記
➂スライス
➃行列の初期化(onesとzeros）
➄assert(検証)

##ソース

・モジュールの導入

```Python
#sklearnモジュールの呼び出し
from sklearn import datasets
import numpy as np
```

・データの読み込み

```Python
#データの読み込み
iris_data=datasets.load_iris()
#データについて、測定値（4種類）とそれに対するラベルについて取得する。
input_data=iris_data.data 
correct_data=iris_data.target 
```

・データの中身の確認

```Python
print(input_data) #左側から「sepal lengh」「sepal width」「petal length」「petal width」
　　　　　　　　　　#sepal⇒がくpetal⇒花弁
>>>
[[5.1 3.5 1.4 0.2]
 [4.9 3.  1.4 0.2]
 [4.7 3.2 1.3 0.2]
 [4.6 3.1 1.5 0.2]
・・・
 [6.5 3.  5.2 2. ]
 [6.2 3.4 5.4 2.3]
 [5.9 3.  5.1 1.8]]

print(correct_data) #0⇒setosa 1⇒vesicolor 2⇒versinica
>>>
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 ・・・ 2 2 2 2 2]

#データ数の確認
len(input_data)
>>>150

#input_dataとcorrect_dataの個数が等しいかを確認
assert len(input_data) == len(correct_data)
>>>True
```

・データの標準化

```Python
#データの平均値の取得
average=np.average(input_data,axis=0)
#データの標準偏差の取得
std=np.std(input_data,axis=0)
#データの標準化(標準値の平均値は0で、標準偏差は１になる)
data=(input_data-average)/std #input_dataは行列だが、averageとstdはベクトルである。⇒ブロードキャストの使用
```

・平均値、標準偏差、標準値の確認

```Python
#四つのデータごとにデータが算出されていることが確認できる。
print("平均値: {}".format(average))
print("標準偏差: {}".format(std))
print("標準値: {}".format(data))
>>>
平均値: [5.84333333 3.05733333 3.758      1.19933333]
標準偏差: [0.82530129 0.43441097 1.75940407 0.75969263]
標準値: [[-9.00681170e-01  1.01900435e+00 -1.34022653e+00 -1.31544430e+00]
・・・ [ 6.86617933e-02 -1.31979479e-01  7.62758269e-01  7.90670654e-01]]
```

・ラベルデータのOne-hot化

```Python
#ラベル配列の長さの取得
correct_data_length=len(correct_data)
#ラベルについてOne-hotで表現する。
correct=np.zeros((correct_data_length,3))
for i in range(correct_data_length):
  correct[i,correct_data[i]]=1.0　#四つのデータごとに、どのラベルに属するか(属するものに対して１と表現する。それ以外は0とする)
```

・One-hot化したラベルデータの中身の確認

```Python
print(correct)#左から順にsetosa,vesicolor,versinica
>>>
[[1. 0. 0.]
 [1. 0. 0.]
 [1. 0. 0.]
 [1. 0. 0.]
 [1. 0. 0.]
・・・
 [0. 0. 1.]
 [0. 0. 1.]
 [0. 0. 1.]]
```

・入力データについて、学習用とテスト用に分割する。

```Python
#indexリストの準備
index=np.arange(correct_data_length)
#入力データ(input_data)のindexについて、奇数と偶数ごとに振り分ける
#[]の中に条件を書く方法は内包表記である。
index_train=index[index%2==0] #偶数行について学習用データとする。
index_test=index[index%2!=0] #奇数行についてテスト用データとする。

#行列のスライスを用いて、実際に学習用とテスト用に分割している。
input_train=input_data[index_train,:]
corrext_train=correct[index_train,:]
input_test=input_data[index_test,:]
corrext_test=correct[index_test,:]
```

##補足

・スライス

```Python
#一次元配列のスライス（ただし、先頭のインデックスは0であることに注意する。）
a=np.array([1,4,5,7,3,9,8])
print(a[1:4]) 
>>>[4 5 7]

#ステップ数2でインデックス1～4の範囲でスライスする。
print(a[1:4:2])
>>>
[4 7]

#二次元配列のスライス
b=np.array([[0,2,4],
            [3,5,9],
            [4,7,8]])
print(b[0,:])#0行のデータをすべて取得する
print(b[:,0])#0列のデータをすべて取得する
>>>
[0 2 4]
[0 3 4]
```

#参考文献
・はじめてのディープラーニング
